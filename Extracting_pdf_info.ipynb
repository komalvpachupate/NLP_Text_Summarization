{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9afca83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supress Warnings\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6acb0be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2\n",
      "  Downloading PyPDF2-1.27.12-py3-none-any.whl (80 kB)\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-1.27.12\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a891c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textractNote: you may need to restart the kernel to use updated packages.\n",
      "  Downloading textract-1.6.5-py3-none-any.whl (23 kB)\n",
      "Collecting pdfminer.six==20191110\n",
      "  Downloading pdfminer.six-20191110-py2.py3-none-any.whl (5.6 MB)\n",
      "Collecting six~=1.12.0\n",
      "  Downloading six-1.12.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting xlrd~=1.2.0\n",
      "  Downloading xlrd-1.2.0-py2.py3-none-any.whl (103 kB)\n",
      "Collecting chardet==3.*\n",
      "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "Collecting beautifulsoup4~=4.8.0\n",
      "  Downloading beautifulsoup4-4.8.2-py3-none-any.whl (106 kB)\n",
      "\n",
      "Collecting extract-msg<=0.29.*\n",
      "  Downloading extract_msg-0.28.7-py2.py3-none-any.whl (69 kB)\n",
      "Collecting python-pptx~=0.6.18\n",
      "  Downloading python-pptx-0.6.21.tar.gz (10.1 MB)\n",
      "Collecting argcomplete~=1.10.0\n",
      "  Downloading argcomplete-1.10.3-py2.py3-none-any.whl (36 kB)\n",
      "Collecting SpeechRecognition~=3.8.1\n",
      "  Downloading SpeechRecognition-3.8.1-py2.py3-none-any.whl (32.8 MB)\n",
      "Collecting docx2txt~=0.8\n",
      "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
      "Collecting pycryptodome\n",
      "  Downloading pycryptodome-3.14.1-cp35-abi3-win_amd64.whl (1.8 MB)\n",
      "Collecting sortedcontainers\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: soupsieve>=1.2 in c:\\users\\komal\\anaconda3\\envs\\nlp\\lib\\site-packages (from beautifulsoup4~=4.8.0->textract) (2.2.1)\n",
      "Collecting olefile>=0.46\n",
      "  Downloading olefile-0.46.zip (112 kB)\n",
      "Collecting imapclient==2.1.0\n",
      "  Downloading IMAPClient-2.1.0-py2.py3-none-any.whl (73 kB)\n",
      "Collecting ebcdic>=1.1.1\n",
      "  Downloading ebcdic-1.1.1-py2.py3-none-any.whl (128 kB)\n",
      "Collecting compressed-rtf>=1.0.6\n",
      "  Downloading compressed_rtf-1.0.6.tar.gz (5.8 kB)\n",
      "Collecting tzlocal>=2.1\n",
      "  Using cached tzlocal-4.2-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\komal\\anaconda3\\envs\\nlp\\lib\\site-packages (from python-pptx~=0.6.18->textract) (4.8.0)\n",
      "Requirement already satisfied: Pillow>=3.3.2 in c:\\users\\komal\\anaconda3\\envs\\nlp\\lib\\site-packages (from python-pptx~=0.6.18->textract) (8.3.2)\n",
      "Collecting XlsxWriter>=0.5.7\n",
      "  Downloading XlsxWriter-3.0.3-py3-none-any.whl (149 kB)\n",
      "Collecting tzdata\n",
      "  Using cached tzdata-2022.1-py2.py3-none-any.whl (339 kB)\n",
      "Collecting pytz-deprecation-shim\n",
      "  Using cached pytz_deprecation_shim-0.1.0.post0-py2.py3-none-any.whl (15 kB)\n",
      "Building wheels for collected packages: docx2txt, compressed-rtf, olefile, python-pptx\n",
      "  Building wheel for docx2txt (setup.py): started\n",
      "  Building wheel for docx2txt (setup.py): finished with status 'done'\n",
      "  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3985 sha256=e7694a56f87298dce680829a9bbfe6199c903c611fe229685ff47321f3505bfb\n",
      "  Stored in directory: c:\\users\\komal\\appdata\\local\\pip\\cache\\wheels\\40\\75\\01\\e6c444034338bde9c7947d3467807f889123465c2371e77418\n",
      "  Building wheel for compressed-rtf (setup.py): started\n",
      "  Building wheel for compressed-rtf (setup.py): finished with status 'done'\n",
      "  Created wheel for compressed-rtf: filename=compressed_rtf-1.0.6-py3-none-any.whl size=6201 sha256=23991a6b8e3d92efd432184ec23e65c95dc7a5e9db613f66c9d9d90259424b6e\n",
      "  Stored in directory: c:\\users\\komal\\appdata\\local\\pip\\cache\\wheels\\e4\\67\\e4\\ba2159853bdd0fe99330aa1e384915108143a5370686ea446f\n",
      "  Building wheel for olefile (setup.py): started\n",
      "  Building wheel for olefile (setup.py): finished with status 'done'\n",
      "  Created wheel for olefile: filename=olefile-0.46-py2.py3-none-any.whl size=35431 sha256=2936af4197b7586b9aea086722f232d91fc8989fc486b7682ffaceebfe6aa79d\n",
      "  Stored in directory: c:\\users\\komal\\appdata\\local\\pip\\cache\\wheels\\64\\b8\\ba\\ebba30390fbd997074f35e42a842ce3fd933213cac8753414e\n",
      "  Building wheel for python-pptx (setup.py): started\n",
      "  Building wheel for python-pptx (setup.py): finished with status 'done'\n",
      "  Created wheel for python-pptx: filename=python_pptx-0.6.21-py3-none-any.whl size=470952 sha256=0383e5d8956e59a12a0ad7a5bda1a1606f629f216f13da6cf58107a6b89e5b84\n",
      "  Stored in directory: c:\\users\\komal\\appdata\\local\\pip\\cache\\wheels\\0e\\4a\\ed\\9653bc799915f52dce3f04d14946fbd85cce9c3cdedc9cfa71\n",
      "Successfully built docx2txt compressed-rtf olefile python-pptx\n",
      "Installing collected packages: tzdata, six, pytz-deprecation-shim, XlsxWriter, tzlocal, sortedcontainers, pycryptodome, olefile, imapclient, ebcdic, compressed-rtf, chardet, xlrd, SpeechRecognition, python-pptx, pdfminer.six, extract-msg, docx2txt, beautifulsoup4, argcomplete, textract\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Successfully uninstalled six-1.16.0\n",
      "  Attempting uninstall: beautifulsoup4\n",
      "    Found existing installation: beautifulsoup4 4.10.0\n",
      "    Uninstalling beautifulsoup4-4.10.0:\n",
      "      Successfully uninstalled beautifulsoup4-4.10.0\n",
      "Successfully installed SpeechRecognition-3.8.1 XlsxWriter-3.0.3 argcomplete-1.10.3 beautifulsoup4-4.8.2 chardet-3.0.4 compressed-rtf-1.0.6 docx2txt-0.8 ebcdic-1.1.1 extract-msg-0.28.7 imapclient-2.1.0 olefile-0.46 pdfminer.six-20191110 pycryptodome-3.14.1 python-pptx-0.6.21 pytz-deprecation-shim-0.1.0.post0 six-1.12.0 sortedcontainers-2.4.0 textract-1.6.5 tzdata-2022.1 tzlocal-4.2 xlrd-1.2.0\n"
     ]
    }
   ],
   "source": [
    "pip install textract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e72064e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Komal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import PyPDF2, urllib.request , nltk , textract\n",
    "from io import BytesIO\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85efe415",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the PDF\n",
    "wFile = urllib.request.urlopen('http://www.udri.org/pdf/02%20working%20paper%201.pdf')\n",
    "pdfreader = PyPDF2.pdf.PdfFileReader(BytesIO(wFile.read()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28b84ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mr.Jagdish Ta', 'Mr.Dinesh Naik', 'Mr.Hiren Daftardar', 'Ms.Anita Naik', 'Mr.Prasad Gharat']\n"
     ]
    }
   ],
   "source": [
    "#extracting page 2 of the docuemnt\n",
    "pageObj = pdfreader.getPage(2)\n",
    "page2 = pageObj.extractText()\n",
    "#Cleaning the text\n",
    "punctuations = ['(',')',';',':','[',']',',','...','.']\n",
    "tokens = word_tokenize(page2)\n",
    "stop_words = stopwords.words('english')\n",
    "keywords = [word for word in tokens if not word in stop_words and not word in punctuations]\n",
    "\n",
    "name_list = list()\n",
    "check =  ['Mr.', 'Mrs.', 'Ms.']\n",
    "for idx, token in enumerate(tokens):\n",
    "    if token.startswith(tuple(check)) and idx < (len(tokens)-1):\n",
    "        name = token + tokens[idx+1] + ' ' +  tokens[idx+2]\n",
    "        name_list.append(name)\n",
    "\n",
    "print(name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85139956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mr.Subodh Kumar', 'Mr.Rajeev Kuknoor', 'Mr.Su dhir', 'Mr.A.G. Marathe', 'Mr.R. Balachandran', 'Mr.V.K Phatak', 'Mr.A.N Kale', 'Mr.A .', 'Mr.Jagdish Talreja', 'Mr.Dinesh Naik', 'Mr.Hiren Daftardar', 'Ms.Anita Naik', 'Mr.Prasad Gharat']\n"
     ]
    }
   ],
   "source": [
    "#extracting page 1 of the docuemnt\n",
    "pageObj = pdfreader.getPage(1)\n",
    "page2 = pageObj.extractText()\n",
    "#Cleaning the text\n",
    "punctuations = ['(',')',';',':','[',']',',','...','.']\n",
    "tokens = word_tokenize(page2)\n",
    "stop_words = stopwords.words('english')\n",
    "keywords = [word for word in tokens if not word in stop_words and not word in punctuations]\n",
    "\n",
    "name_list = list()\n",
    "check =  ['Mr.', 'Mrs.', 'Ms.']\n",
    "for idx, token in enumerate(tokens):\n",
    "    if token.startswith(tuple(check)) and idx < (len(tokens)-1):\n",
    "        name = token + tokens[idx+1] + ' ' +  tokens[idx+2]\n",
    "        name_list.append(name)\n",
    "\n",
    "print(name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "932d1c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "wFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980febc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "a0f46594",
   "metadata": {},
   "source": [
    "link:   https://medium.com/mlearning-ai/how-to-extract-text-from-a-pdf-nlp-b6409422cfd2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211d6d45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
